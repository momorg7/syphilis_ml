{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#Package imports\n","\n","Import the necessary packages and mount the drive"],"metadata":{"id":"NbZdKChtakuu"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lmTSZxd1RcW4","executionInfo":{"status":"ok","timestamp":1678989751269,"user_tz":180,"elapsed":27365,"user":{"displayName":"Morgana T","userId":"00683347594947221328"}},"outputId":"9ec11445-fb8a-4de4-852d-e67c17e8921a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["import pandas as pd\n","import numpy as np\n","\n","from sklearn.preprocessing import MinMaxScaler\n","from google.colab import drive\n","\n","drive.mount('/content/gdrive', force_remount=True)"]},{"cell_type":"markdown","source":["#Action\n","\n","Read the dataset as a dataframe, analyze the missing data quantity, impute the missing data with the most frequent value and normalize the data"],"metadata":{"id":"V4ciQVY5azQo"}},{"cell_type":"code","source":["path = 'PATH_TO_DATASET_IN_DRIVE'\n","dataset_name = 'DATASET_NAME'\n","\n","df = pd.read_csv(path+dataset_name+\".csv\", sep=',') # read the dataset csv"],"metadata":{"id":"tpGUPzdoasCU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.shape # analysing size of rows and columns of dataframe"],"metadata":{"id":"I0V-WgJQbXZh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.isna().sum() # analyze quantity of missing data"],"metadata":{"id":"MDGA3Z41bXyS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for col in df.columns: # fill the missing data with the most frequent value\n","  df[col] = df[col].fillna(df[col].mode()[0])"],"metadata":{"id":"sI51V23lN5ly"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_normalized = df.copy() # create a copy of the dataframe\n","\n","scaler = MinMaxScaler()\n","df_normalized[df_normalized.columns] = scaler.fit_transform(df_normalized[df_normalized.columns]) # normalize the data\n","\n","df_normalized.to_csv(path+'DATASET_NORMALIZED.csv', sep=',', index=False) # save"],"metadata":{"id":"xHGgqDv4M1MZ"},"execution_count":null,"outputs":[]}]}